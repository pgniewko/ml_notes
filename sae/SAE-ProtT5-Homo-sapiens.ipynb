{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350f2916-90ff-406e-9b51-e77e2ee95b48",
   "metadata": {},
   "source": [
    "Data downloaded from (access data 09/21/2025): https://www.uniprot.org/help/embeddings?utm_source=chatgpt.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cdb334-455c-4005-94f6-98728b52c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins: 20660\n",
      "First 5 IDs: ['A0A024R1R8', 'A0A024RBG1', 'A0A024RCN7', 'A0A075B6H5', 'A0A075B6H7']\n",
      "\n",
      "Protein ID: A0A024R1R8\n",
      "Embedding shape: (1024,)\n",
      "[ 0.013664  0.03848   0.03925  -0.0675   -0.0247    0.03268  -0.0171\n",
      " -0.10223   0.014656  0.01147 ]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Path to your downloaded file\n",
    "file_path = \"./data/per-protein.h5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    # List all protein IDs stored\n",
    "    protein_ids = list(f.keys())\n",
    "    print(f\"Number of proteins: {len(protein_ids)}\")\n",
    "    print(\"First 5 IDs:\", protein_ids[:5])\n",
    "\n",
    "    # Access embeddings for a specific protein (by UniProt ID)\n",
    "    prot_id = protein_ids[0]  # pick the first one\n",
    "    embedding = f[prot_id][()]  # retrieve as a numpy array\n",
    "\n",
    "    print(f\"\\nProtein ID: {prot_id}\")\n",
    "    print(f\"Embedding shape: {embedding.shape}\")\n",
    "    print(embedding[:10])  # show first 10 numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483d0b18-68eb-45b8-ac23-76bd308a0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUPYTER CELL: Gumbel-Top-k → anneal to hard Top-k (no aux loss)\n",
    "# ----------------------------------------------------------------------------------\n",
    "# This notebook cell implements a sparse autoencoder that:\n",
    "# - Uses per-sample LayerNorm (batch-independent inference)\n",
    "# - Starts with a relaxed (Gumbel-Top-k-inspired) soft activation\n",
    "# - Anneals temperature and mixes into hard Top-k over training\n",
    "# - Trains on per-protein embeddings loaded from an HDF5 file\n",
    "# - Splits into train/val/test (80/10/10)\n",
    "# - Logs & plots MSE and MAE vs iteration (train/val/test)\n",
    "#\n",
    "# Assumes your HDF5 file structure is:\n",
    "#   keys: UniProt IDs (e.g., \"A0A024R1R8\")\n",
    "#   values: float arrays of shape (1024,)\n",
    "#\n",
    "# Example info you pasted:\n",
    "# Number of proteins: 20660\n",
    "# First 5 IDs: ['A0A024R1R8', 'A0A024RBG1', 'A0A024RCN7', 'A0A075B6H5', 'A0A075B6H7']\n",
    "# One embedding shape: (1024,)\n",
    "#\n",
    "# You can customize paths & hyperparameters in the CONFIG section below.\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import Callable, Any, Tuple, Dict, List, Optional\n",
    "\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edit as desired)\n",
    "# =========================\n",
    "H5_PATH       = \"./data/per-protein.h5\"  # path to your HDF5 embeddings\n",
    "TOP_K         = 32                       # desired k\n",
    "HIDDEN_MULT   = 4                        # hidden_dim = HIDDEN_MULT * input_dim\n",
    "BATCH_SIZE    = 1024\n",
    "EPOCHS        = 10\n",
    "LR            = 1e-3\n",
    "EVAL_EVERY    = 200                      # evaluate/log every N train iterations\n",
    "NUM_WORKERS   = 2\n",
    "SPLIT_SEED    = 123\n",
    "\n",
    "# Relaxed → Hard annealing\n",
    "TAU_START     = 1.0                      # initial temperature for soft (higher = softer)\n",
    "TAU_END       = 0.05                     # final temperature for soft (near-hard)\n",
    "WARMUP_STEPS  = 2000                     # number of iterations to anneal tau & mix alpha\n",
    "# alpha schedule: 0 → 1 over WARMUP_STEPS (0 = fully soft, 1 = fully hard)\n",
    "\n",
    "# =========================\n",
    "# Utilities & reproducibility\n",
    "# =========================\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =========================\n",
    "# Per-sample LayerNorm (batch-independent)\n",
    "# =========================\n",
    "def LN(x: torch.Tensor, eps: float = 1e-5) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Per-sample layer-norm across features (last dim).\n",
    "    Returns (x_norm, mu, std) for undoing later.\n",
    "    \"\"\"\n",
    "    mu = x.mean(dim=-1, keepdim=True)\n",
    "    xc = x - mu\n",
    "    std = torch.sqrt((xc * xc).mean(dim=-1, keepdim=True) + eps)\n",
    "    x_norm = xc / std\n",
    "    return x_norm, mu, std\n",
    "\n",
    "# =========================\n",
    "# Activation helpers\n",
    "# =========================\n",
    "def hard_topk_relu(x: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Hard Top-k after ReLU (non-differentiable selection, standard STE-like behavior).\n",
    "    \"\"\"\n",
    "    x = F.relu(x)\n",
    "    if k >= x.shape[-1]:\n",
    "        return x\n",
    "    vals, idxs = torch.topk(x, k=k, dim=-1, largest=True, sorted=False)\n",
    "    out = torch.zeros_like(x)\n",
    "    out.scatter_(-1, idxs, vals)\n",
    "    return out\n",
    "\n",
    "def gumbel_noise_like(x: torch.Tensor, eps: float = 1e-9) -> torch.Tensor:\n",
    "    u = torch.rand_like(x)\n",
    "    return -torch.log(-torch.log(u + eps) + eps)\n",
    "\n",
    "def cosine_anneal(start: float, end: float, t: float) -> float:\n",
    "    \"\"\"\n",
    "    Cosine annealing from start→end with t in [0,1].\n",
    "    \"\"\"\n",
    "    return end + 0.5*(start - end)*(1 + math.cos(math.pi * t))\n",
    "\n",
    "class RelaxedTopK(nn.Module):\n",
    "    \"\"\"\n",
    "    Gumbel-Top-k inspired soft activation + annealing into hard Top-k.\n",
    "\n",
    "    Forward uses:\n",
    "      - Soft branch: softmax((ReLU(z) + gumbel)/tau) as a distribution over units,\n",
    "        then produces a soft activation vector whose L1 mass roughly matches the\n",
    "        \"energy\" in ReLU(z). We form h_soft = soft_probs * sum(ReLU(z)) to keep scale.\n",
    "      - Hard branch: standard hard_topk_relu(z, k).\n",
    "      - Mix: h = (1 - alpha) * h_soft + alpha * h_hard, with alpha rising from 0→1\n",
    "        over WARMUP_STEPS; tau decays from TAU_START→TAU_END over the same window.\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int, tau_start: float, tau_end: float, warmup_steps: int):\n",
    "        super().__init__()\n",
    "        self.k = int(k)\n",
    "        self.tau_start = float(tau_start)\n",
    "        self.tau_end = float(tau_end)\n",
    "        self.warmup_steps = int(warmup_steps)\n",
    "        self.register_buffer(\"step\", torch.tensor(0, dtype=torch.long), persistent=False)\n",
    "\n",
    "    def update_step(self):\n",
    "        self.step += 1\n",
    "\n",
    "    def _tau_alpha(self) -> Tuple[float, float]:\n",
    "        # Progress in [0, 1]\n",
    "        t = float(min(int(self.step.item()), self.warmup_steps)) / max(1, self.warmup_steps)\n",
    "        tau = cosine_anneal(self.tau_start, self.tau_end, t)\n",
    "        alpha = t  # linear 0 → 1\n",
    "        return tau, alpha\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        tau, alpha = self._tau_alpha()\n",
    "        # Soft branch\n",
    "        z_pos = F.relu(z)\n",
    "        if self.training:\n",
    "            g = gumbel_noise_like(z_pos)\n",
    "        else:\n",
    "            # At eval, no gumbel noise; still allow soft if not fully annealed\n",
    "            g = torch.zeros_like(z_pos)\n",
    "\n",
    "        logits = (z_pos + g) / max(tau, 1e-6)\n",
    "        soft_probs = torch.softmax(logits, dim=-1)  # distribution over units\n",
    "        mass = z_pos.sum(dim=-1, keepdim=True).clamp_min(1e-6)\n",
    "        h_soft = soft_probs * mass  # soft \"allocation\" of mass\n",
    "\n",
    "        # Hard branch\n",
    "        h_hard = hard_topk_relu(z, self.k)\n",
    "\n",
    "        # Mix\n",
    "        h = (1.0 - alpha) * h_soft + alpha * h_hard\n",
    "        # Update internal step counter\n",
    "        if self.training:\n",
    "            self.update_step()\n",
    "        return h\n",
    "\n",
    "# =========================\n",
    "# Autoencoder (with pre-bias, tied/untied decoder, optional normalize)\n",
    "# =========================\n",
    "class TiedTranspose(nn.Module):\n",
    "    def __init__(self, linear: nn.Linear):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        assert self.linear.bias is None\n",
    "        return F.linear(x, self.linear.weight.t(), bias=None)\n",
    "    @property\n",
    "    def weight(self) -> torch.Tensor:\n",
    "        return self.linear.weight.t()\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    x' = preprocess(x)                 # optional per-sample LN\n",
    "    z  = (x' - pre_bias) @ W_enc^T + latent_bias\n",
    "    h  = activation(z)                 # RelaxedTopK (anneals to hard)\n",
    "    y' = decoder(h) + pre_bias\n",
    "    y  = unprocess(y')                 # undo LN (if applied)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_latents: int,\n",
    "        n_inputs: int,\n",
    "        activation: nn.Module,\n",
    "        tied: bool = False,\n",
    "        normalize: bool = True,\n",
    "        enc_init: str = \"xavier\",\n",
    "        dec_init: str = \"xavier\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.pre_bias = nn.Parameter(torch.zeros(n_inputs))\n",
    "        self.encoder = nn.Linear(n_inputs, n_latents, bias=False)\n",
    "        if enc_init == \"kaiming\":\n",
    "            nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.encoder.weight)\n",
    "\n",
    "        self.latent_bias = nn.Parameter(torch.zeros(n_latents))\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        if tied:\n",
    "            self.decoder = TiedTranspose(self.encoder)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(n_latents, n_inputs, bias=False)\n",
    "            if dec_init == \"kaiming\":\n",
    "                nn.init.kaiming_uniform_(self.decoder.weight, a=math.sqrt(5))\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(self.decoder.weight)\n",
    "\n",
    "    def preprocess(self, x: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        if not self.normalize:\n",
    "            return x, {}\n",
    "        x_norm, mu, std = LN(x)\n",
    "        return x_norm, {\"mu\": mu, \"std\": std}\n",
    "\n",
    "    def encode_pre_act(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x - self.pre_bias\n",
    "        return F.linear(x, self.encoder.weight, self.latent_bias)\n",
    "\n",
    "    def decode(self, h: torch.Tensor, info: Optional[Dict[str, torch.Tensor]] = None) -> torch.Tensor:\n",
    "        y_prime = self.decoder(h) + self.pre_bias\n",
    "        if self.normalize:\n",
    "            assert info is not None\n",
    "            y_prime = y_prime * info[\"std\"] + info[\"mu\"]\n",
    "        return y_prime\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x_p, info = self.preprocess(x)\n",
    "        z = self.encode_pre_act(x_p)\n",
    "        h = self.activation(z)\n",
    "        y = self.decode(h, info)\n",
    "        return z, h, y\n",
    "\n",
    "# =========================\n",
    "# Data (HDF5) + splits\n",
    "# =========================\n",
    "class H5ProteinEmbeddings(Dataset):\n",
    "    \"\"\"HDF5 with {protein_id: embedding_vector}.\"\"\"\n",
    "    def __init__(self, h5_path: str, ids: Optional[List[str]] = None):\n",
    "        super().__init__()\n",
    "        self.h5_path = h5_path\n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            all_ids = list(f.keys())\n",
    "        self.ids = all_ids if ids is None else ids\n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            self.input_dim = int(f[self.ids[0]][()].shape[-1])\n",
    "        self._f = None\n",
    "\n",
    "    def __len__(self): return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        if self._f is None:\n",
    "            self._f = h5py.File(self.h5_path, \"r\")\n",
    "        x = self._f[self.ids[i]][()].astype(\"float32\")\n",
    "        return torch.from_numpy(x)\n",
    "\n",
    "# =========================\n",
    "# Evaluation\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    tot_mse = 0.0\n",
    "    tot_mae = 0.0\n",
    "    n_elems = 0\n",
    "    for xb in loader:\n",
    "        xb = xb.to(device)\n",
    "        _, _, yb = model(xb)\n",
    "        tot_mse += F.mse_loss(yb, xb, reduction=\"sum\").item()\n",
    "        tot_mae += F.l1_loss(yb, xb, reduction=\"sum\").item()\n",
    "        n_elems += xb.numel()\n",
    "    return tot_mse / n_elems, tot_mae / n_elems\n",
    "\n",
    "# =========================\n",
    "# Training loop\n",
    "# =========================\n",
    "def train_relaxed_topk_sae(\n",
    "    h5_path=H5_PATH,\n",
    "    k=TOP_K,\n",
    "    hidden_mult=HIDDEN_MULT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    eval_every=EVAL_EVERY,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    split_seed=SPLIT_SEED,\n",
    "    tau_start=TAU_START,\n",
    "    tau_end=TAU_END,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    tied=False,\n",
    "    normalize=True,\n",
    "):\n",
    "    # ---- Load IDs & split 80/10/10 ----\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ids = list(f.keys())\n",
    "    rng = np.random.default_rng(split_seed)\n",
    "    rng.shuffle(ids)\n",
    "    n = len(ids); n_tr = int(0.8*n); n_va = int(0.1*n)\n",
    "    tr_ids = ids[:n_tr]; va_ids = ids[n_tr:n_tr+n_va]; te_ids = ids[n_tr+n_va:]\n",
    "\n",
    "    train_ds = H5ProteinEmbeddings(h5_path, tr_ids)\n",
    "    val_ds   = H5ProteinEmbeddings(h5_path, va_ids)\n",
    "    test_ds  = H5ProteinEmbeddings(h5_path, te_ids)\n",
    "\n",
    "    input_dim = train_ds.input_dim\n",
    "    hidden_dim = hidden_mult * input_dim\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # ---- Model ----\n",
    "    act = RelaxedTopK(k=k, tau_start=tau_start, tau_end=tau_end, warmup_steps=warmup_steps)\n",
    "    model = Autoencoder(\n",
    "        n_latents=hidden_dim,\n",
    "        n_inputs=input_dim,\n",
    "        activation=act,\n",
    "        tied=tied,\n",
    "        normalize=normalize,\n",
    "        enc_init=\"xavier\",\n",
    "        dec_init=\"xavier\",\n",
    "    ).to(device)\n",
    "\n",
    "    # ---- Optimizer ----\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # ---- History ----\n",
    "    hist: Dict[str, List[float]] = {\n",
    "        \"iter\": [], \"train_mse\": [], \"val_mse\": [], \"test_mse\": [],\n",
    "        \"train_mae\": [], \"val_mae\": [], \"test_mae\": []\n",
    "    }\n",
    "\n",
    "    it = 0\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for xb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            _, _, yb = model(xb)\n",
    "            loss = F.mse_loss(yb, xb, reduction=\"mean\")\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "            it += 1\n",
    "            if it % eval_every == 0:\n",
    "                train_mse = loss.item()\n",
    "                train_mae = F.l1_loss(yb.detach(), xb, reduction=\"mean\").item()\n",
    "                val_mse, val_mae   = evaluate(model, val_loader, device)\n",
    "                test_mse, test_mae = evaluate(model, test_loader, device)\n",
    "\n",
    "                hist[\"iter\"].append(it)\n",
    "                hist[\"train_mse\"].append(train_mse)\n",
    "                hist[\"val_mse\"].append(val_mse)\n",
    "                hist[\"test_mse\"].append(test_mse)\n",
    "                hist[\"train_mae\"].append(train_mae)\n",
    "                hist[\"val_mae\"].append(val_mae)\n",
    "                hist[\"test_mae\"].append(test_mae)\n",
    "\n",
    "        # End-of-epoch status\n",
    "        if hist[\"iter\"]:\n",
    "            print(f\"Epoch {ep:02d} | last train MSE {hist['train_mse'][-1]:.6f} | \"\n",
    "                  f\"val MSE {hist['val_mse'][-1]:.6f} | test MSE {hist['test_mse'][-1]:.6f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {ep:02d} | (no eval yet; decrease EVAL_EVERY to log sooner)\")\n",
    "\n",
    "    # ---- Save weights ----\n",
    "    torch.save(\n",
    "        {\"state_dict\": model.state_dict(),\n",
    "         \"config\": {\n",
    "             \"input_dim\": input_dim,\n",
    "             \"hidden_dim\": hidden_dim,\n",
    "             \"k\": k,\n",
    "             \"tau_start\": tau_start,\n",
    "             \"tau_end\": tau_end,\n",
    "             \"warmup_steps\": warmup_steps,\n",
    "             \"tied\": tied,\n",
    "             \"normalize\": normalize,\n",
    "         }},\n",
    "        \"relaxed_topk_sae.pt\",\n",
    "    )\n",
    "\n",
    "    # ---- Plots ----\n",
    "    if hist[\"iter\"]:\n",
    "        plt.figure()\n",
    "        plt.plot(hist[\"iter\"], hist[\"train_mse\"], label=\"train MSE\")\n",
    "        plt.plot(hist[\"iter\"], hist[\"val_mse\"],   label=\"val MSE\")\n",
    "        plt.plot(hist[\"iter\"], hist[\"test_mse\"],  label=\"test MSE\")\n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"MSE\"); plt.title(\"MSE vs Iteration (Relaxed→Hard Top-k SAE)\"); plt.legend()\n",
    "        plt.savefig(\"relaxed_topk_sae_mse.png\", bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(hist[\"iter\"], hist[\"train_mae\"], label=\"train MAE\")\n",
    "        plt.plot(hist[\"iter\"], hist[\"val_mae\"],   label=\"val MAE\")\n",
    "        plt.plot(hist[\"iter\"], hist[\"test_mae\"],  label=\"test MAE\")\n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"MAE\"); plt.title(\"MAE vs Iteration (Relaxed→Hard Top-k SAE)\"); plt.legend()\n",
    "        plt.savefig(\"relaxed_topk_sae_mae.png\", bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "    return model, hist\n",
    "\n",
    "# =========================\n",
    "# Run training\n",
    "# =========================\n",
    "# model, history = train_relaxed_topk_sae()\n",
    "# After running:\n",
    "#   - Check \"relaxed_topk_sae.pt\" for weights & config\n",
    "#   - \"relaxed_topk_sae_mse.png\" and \"relaxed_topk_sae_mae.png\" for curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c5fec-432b-49ce-bbbc-d76511e09945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'H5ProteinEmbeddings' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'H5ProteinEmbeddings' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1859, 1860) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 1859) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_relaxed_topk_sae\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 341\u001b[0m, in \u001b[0;36mtrain_relaxed_topk_sae\u001b[0;34m(h5_path, k, hidden_mult, batch_size, epochs, lr, eval_every, num_workers, split_seed, tau_start, tau_end, warmup_steps, tied, normalize)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    340\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    342\u001b[0m         xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m         _, _, yb \u001b[38;5;241m=\u001b[39m model(xb)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1264\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1263\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1859, 1860) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model, history = train_relaxed_topk_sae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfbd37-49f9-4de0-a18c-7d651c09bef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
